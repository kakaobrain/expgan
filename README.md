# Exp-GAN: 3D-Aware Facial Image Generation with Expression Control

![image](https://user-images.githubusercontent.com/29425882/194230500-ca3f9337-d540-4194-8d96-008d420fde7a.png)

This repository is the official implementation of the ACCV 2022 paper Exp-GAN: 3D-Aware Facial Image Generation with Expression Control.

Yeonkyeong Lee, Taeho Choi, Hyunsung Go, Hyunjoon Lee, Sunghyun Cho, and Junho Kim.


## Installation

Requirements for using pytorch3d
- Python >= 3.7
- PyTorch >= 1.12.0
```
pip install -r requirements.txt
git clone https://github.com/facebookresearch/pytorch3d.git
cd pytorch3d
git checkout v0.7.0
pip install -e .
cd -
```

## Dataset and model

Download the aligned FFHQ dataset images from [the official repository](https://drive.google.com/open?id=1tZUcXDBeOibC6jcMCtgRRz67pzrAHeHL),
and place them under `data/FFHQ/img`.

Annotations for DECA parameters from FFHQ dataset (head pose, shape and expression) can be downloaded below(place the files under `data/FFHQ/annots`)
- [ffhq_deca_ear_ortho.pkl](https://t1.kakaocdn.net/humancv/expgan/dataset/ffhq_deca_ear_ortho.pkl)
- [ffhq_deca_ear_ortho_flipped.json](https://t1.kakaocdn.net/humancv/expgan/dataset/ffhq_deca_ear_ortho_flipped.json)



DECA is used to generate facial texture, download required assets by running 
```
cd data
sh download_deca.sh
cd -
```

Below we present the dataset folder tree:
```
data/
└── DECA/
    ├── data/
    └── indices_ear_noeye.pkl
└── demo/
    └── meta_smooth.json
└── FFHQ/
    ├── annots/
        ├── ffhq_deca_ear_ortho_flipped.json
        └── ffhq_deca_ear_ortho.pkl
    └── img/
```

Please refer `experiments/config/config.yaml` to see how the data is used.

<!-- - dataset:
    - FFHQ : 
        - dataset_root: `data/FFHQ/`
        - images: `<dataset_root>/img`
        - DECA parameters: `<dataset_root>/ffhq_deca_ear_ortho_1217.pkl`, `<dataset_root>/ffhq_deca_ear_ortho_flipped_0207.json`
        - masking indices : `<dataset_root>/indices_ear_noeye.pkl`

    - DECA : `data/DECA/`

- pre-trained model : `data/pretrained_checkpoint/is_alpha10.ckpt`
- config : `data/pretrained_checkpoint/is_alpha10_config.yaml` -->


## Training
Run the following script to train our model:
```
sh ./experiments/ffhq/train.sh
```

## evaluation
A pretrained model can be downloaded [here](https://t1.kakaocdn.net/humancv/expgan/model/model_checkpoint.ckpt). Place the model file under `pretrained_model/model_checkpoint.ckpt`.
<!-- ; refer the demo notebook file to see how to use the checkpoint. -->

Run the following script to generate images for the FID evaluation:
```
python eval.py --cfg <cfg> --ckpt <ckpt> --savedir <savedir>
```

Then run the following to measure the FID between generated and real images:
```
python fid.py --root_real <root_real> --root_fake <root_fake> --batch_size 50
```
where `<root_real>` contains downsampled FFHQ images and `<root_fake>` contains images generated by `eval.py`.


## Demo

Please check `demo.ipynb` to see how to generate some examples by using a pretrained model.

### Pose interpolation
https://user-images.githubusercontent.com/29425882/196860527-eff17dde-0c6f-4a54-82fa-73b169dfb667.mp4

![pose_interp](https://user-images.githubusercontent.com/29425882/196859994-a825bbc7-e0f1-431b-857e-d79282edd767.png)

### Expression interpolation
https://user-images.githubusercontent.com/29425882/196860094-f403301f-27fa-41be-b6b1-d358f3826b71.mp4

![expression_interp](https://user-images.githubusercontent.com/29425882/196859810-e6c93200-9c22-4def-ad2e-4457bc3b93c8.png)

### Pose and expression interpolation
https://user-images.githubusercontent.com/29425882/196860427-2a911e91-5be5-4c98-aa06-9455b4c807ce.mp4

### Low- and high-resolution results before and after StyleGAN upsampling
https://user-images.githubusercontent.com/29425882/196860562-1e5bd71f-3c76-45ce-9040-f355396dc3d4.mp4

### Shape interpolation
![shape_interp](https://user-images.githubusercontent.com/29425882/196860016-2d4b9fc7-3d55-408c-9429-7e27e925083b.png)

### Latent vector (w space) interpolation
![identity_interp](https://user-images.githubusercontent.com/29425882/196859905-eedd4a05-98e4-4f84-b2b1-e1f92f12676a.png)

## Contact
This project is maintained by 
- Taeho Choi(major.1965@kakaobrain.com)
- Yeonkyeong Lee(mag.i@kakaobrain.com)
- Hyunjoon Lee(malfo.lee@kakaobrain.com)

## License
Copyright (c) 2022 POSTECH, Kookmin University, Kakao Brain Corp. All Rights Reserved. Licensed under the Apache License, Version 2.0 (see [LICENSE](./LICENSE) for details)
